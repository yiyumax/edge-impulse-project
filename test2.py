#!/usr/bin/env python3
import sys
import cv2
import numpy as np
from edge_impulse_linux.runner import ImpulseRunner


def load_and_preprocess(image_path, width, height):
    """è®€å–åœ–ç‰‡ä¸¦ä¾æ¨¡å‹éœ€æ±‚åšå‰è™•ç†ï¼Œå›å‚³ features ä»¥åŠåŸåœ– (çµ¦ç•«æ¡†ç”¨)"""
    img_bgr = cv2.imread(image_path)
    if img_bgr is None:
        raise RuntimeError(f"è®€ä¸åˆ°åœ–ç‰‡ï¼š{image_path}")

    # å…ˆè½‰ RGB å† resizeï¼ˆè·Ÿ Edge Impulse ç¯„ä¾‹ä¸€è‡´ï¼‰
    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
    img_resized = cv2.resize(img_rgb, (width, height))

    # é€™è£¡ç”¨ç°éšç•¶è¼¸å…¥
    img_gray = cv2.cvtColor(img_resized, cv2.COLOR_RGB2GRAY)
    img_gray = img_gray.astype(np.float32)

    # æ”¤å¹³æˆä¸€ç¶­é™£åˆ—ç•¶ä½œæ¨¡å‹ input
    features = img_gray.flatten()
    return img_bgr, features, img_resized.shape[1], img_resized.shape[0]


def draw_bounding_boxes(orig_img, boxes, model_w, model_h, save_path="result.jpg"):
    """æŠŠ bounding box ç•«åœ¨åŸåœ–ä¸Šä¸¦å­˜æª”"""
    h, w = orig_img.shape[:2]
    # æ¨¡å‹è¼¸å…¥å°ºå¯¸ -> åŸåœ–å°ºå¯¸ çš„ç¸®æ”¾æ¯”ä¾‹
    scale_x = w / float(model_w)
    scale_y = h / float(model_h)

    for box in boxes:
        x = int(box["x"] * scale_x)
        y = int(box["y"] * scale_y)
        bw = int(box["width"] * scale_x)
        bh = int(box["height"] * scale_y)

        label = box["label"]
        score = box["value"]

        # ç•«æ¡†
        cv2.rectangle(orig_img, (x, y), (x + bw, y + bh), (0, 255, 0), 2)
        # ç•«æ¨™ç±¤æ–‡å­—
        text = f"{label} {score:.2f}"
        cv2.putText(
            orig_img,
            text,
            (x, max(0, y - 10)),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.6,
            (0, 255, 0),
            2,
            cv2.LINE_AA,
        )

    cv2.imwrite(save_path, orig_img)
    print(f"å·²å°‡åµæ¸¬çµæœå­˜æˆï¼š{save_path}")


def main():
    if len(sys.argv) != 3:
        print("ä½¿ç”¨æ–¹å¼: python3 classify_od.py <model.eim> <åœ–ç‰‡æª”>")
        print("  ç¯„ä¾‹:   python3 classify_od.py ./model.eim test.jpg")
        sys.exit(1)

    model_path = sys.argv[1]
    image_path = sys.argv[2]

    print(f"è¼‰å…¥æ¨¡å‹: {model_path}")
    print(f"è¼‰å…¥åœ–ç‰‡: {image_path}")

    runner = ImpulseRunner(model_path)

    try:
        # åˆå§‹åŒ–æ¨¡å‹
        model_info = runner.init()
        labels = model_info["model_parameters"]["labels"]
        model_w = model_info["model_parameters"]["image_input_width"]
        model_h = model_info["model_parameters"]["image_input_height"]
        print(f"æ¨¡å‹æ¨™ç±¤ï¼š{labels}")
        print(f"æ¨¡å‹è¼¸å…¥å°ºå¯¸ï¼š{model_w} x {model_h}")

        # è®€åœ– + å‰è™•ç†
        orig_img, features, _, _ = load_and_preprocess(image_path, model_w, model_h)

        # æ¨è«–
        result = runner.classify(features)

        # æ–‡å­—åˆ—å°çµæœ
        if "bounding_boxes" in result["result"]:
            boxes = result["result"]["bounding_boxes"]
            print(f"åµæ¸¬åˆ° {len(boxes)} å€‹ç‰©ä»¶ï¼š")
            for i, box in enumerate(boxes, start=1):
                print(f"ç‰©ä»¶{i}: {box['label']} ({box['value']:.2f})")
        else:
            print("çµæœä¸­æ²’æœ‰ bounding_boxes æ¬„ä½ï¼š")
            print(result)

        # ğŸ” è¦–è¦ºåŒ–ï¼šç•«æ¡† + å­˜æˆ result.jpg
        if "bounding_boxes" in result["result"]:
            draw_bounding_boxes(
                orig_img,
                result["result"]["bounding_boxes"],
                model_w,
                model_h,
                "results/result.jpg",
            )

    finally:
        runner.stop()


if __name__ == "__main__":
    main()
